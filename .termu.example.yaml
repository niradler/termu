model:
  provider: ollama
  name: qwen3:latest
  server: http://127.0.0.1:11434
  timeout: 60
# Optional settings for OpenAI-compatible servers
# model:
#   provider: "openai"           # Use "openai" for OpenAI-compatible servers
#   name: "gpt-4o"                # Model name (depends on your LiteLLM configuration)
#   api_key: "sk-..."           # Your API key (required)
#   base_url: "http://localhost:4000/v1" # Base URL of your OpenAI-compatible server
#   timeout: 60  

security:
  allowed_commands:
    - sd
    - fd
    - rg
    - bat
    - xsv
    - jaq
    - yq
    - dua
    - eza
    - ls
    - cat
    - grep
    - find
    - echo
    - pwd
    - cd
    - git
    - curl
    - wget
    - cp
    - mv
    - mkdir
    - touch

  restricted_folders:
    - /System
    - /Windows
    - /etc/passwd
    - /etc/shadow
    - ~/.ssh
    - ~/.aws

  allowed_folders:
    - ./
    - ~/Documents
    - ~/Projects

  high_risk_commands:
    - rm
    - mv
    - chmod
    - chown
    - sudo

  blocked_patterns:
    - "rm -rf /"
    - "rm -rf *"
    - ":(){ :|:& };:"
    - "mkfs"
    - "dd if="
    - "> /dev/sda"

logging:
  level: info
  file: ~/.olloco/logs/olloco.log
